Existen muchas redes distintas con numerosos protocolos con un uso muy difundido a través de estas, en cada capa. Es necesario estudiar con cuidado los aspectos que surgen cuando se conectan dos o más redes para formar una **interred** o simplemente una **internet**.

Como por lo general las redes difrieren en formas importantes, no siempre es tan sencillo enviar paquetes de una red a otra. Debemos lidiar con problemas de heterogeneidad y también con problemas de escala a medida que la interred resultante aumenta su tamaño en forma considerable.

### ¿Cómo se pueden conectar las redes?
Existen dos opciones básicas para conectar distintas redes: podemos construir dispositivos que traduzcan o conviertan los paquetes de cada tipo de red en paquetes para otra red o, como buenos científicos de la computación, podemos tratar de resolver el problema al agregar una capa de indirección y construir una capa común encima de las distintas redes. En cualquier caso, los dispositivos se colocan en los límites entre las redes.

Desde un principio, Cerf y Kahn (1974) abogaron por una capa común para ocultar las diferencias de las redes existentes. Esta metodología ha tenido un gran éxito, y la capa que propusieron se separó eventualmente en los protocolos TCP e IP. Casi cuatro décadas después, IP es la base de la Internet moderna. IP proporciona un formato de paquete universal que todos los enrutadores reconocen y que se puede pasar casi por cualquier red. IP ha extendido su alcance de las redes de computadoras para apoderarse de la red telefónica. También opera en redes de sensores y en otros dispositivos pequeños que alguna vez se consideraron con recursos demasiado restringidos como para soportarlo.

### Tunelización
Es en extremo difícil manejar el caso general de hacer que dos redes distintas se interconecten. Sin embargo, hay un caso especial que se puede manejar, incluso para distintos protocolos de red. Este caso es cuando el host de origen y el de destino están en el mismo tipo de red, pero hay una red diferente en medio. Como ejemplo, piense en un banco internacional con una red IPv6 en París, una en Londres y una conectividad entre las oficinas a través de la Internet IPv4.

La solución a este problema es una técnica llamada **tunelización** (tunneling). Para enviar un paquete IP a un host en la oficina de Londres, un host en la oficina de París construye el paquete que contiene una dirección IPv6 en Londres y la envía al enrutador multiprotocolo que conecta la red IPv6 de París con la Internet IPv4. Cuando este enrutador recibe el paquete IPv6, lo encapsula con un encabezado IPv4 dirigido al lado IPv4 del enrutador multiprotocolo que se conecta con la red IPv6 de Londres. Es decir, el enrutador coloca un paquete (IPv6) dentro de un paquete (IPv4). Cuando llega este paquete envuelto, el enrutador de Londres extrae el paquete IPv6 original y lo envía hacia el host de destino.

La desventaja de la tunelización es que no se puede llegar a ninguno de los hosts en la red que se tuneliza debido a que los paquetes no pueden escapar a mitad del túnel. Sin embargo, esta limitación de los túneles se convierte en una ventaja gracias a las redes [[VPN]] (Virtual Private Network).

### Enrutamiento entre redes
El enrutamiento a través de una interred presenta el mismo problema que el enrutamiento en una sola red, pero con algunas complicaciones adicionales. Para empezar, las redes pueden usar internamente distintos algoritmos de enrutamiento. Por ejemplo, una red podría usar un enrutamiento por estado del enlace y otra un enrutamiento por vector de distancia. Como los algoritmos de estado del enlace necesitan conocer la topología pero los algoritmos de vector de distancia no, tan sólo esta diferencia dificultaría mucho el proceso de encontrar las rutas más cortas a través de la internet.

Las redes manejadas por distintos operadores conducen a problemas más grandes. En primer lugar, tal vez los operadores tengan distintas ideas sobre lo que sería una buena ruta a través de la red. Posiblemente un operador quiera la ruta con el menor retardo, mientras que otro prefiera la ruta menos costosa. Esto obligará a los operadores a usar distintas cantidades para establecer los costos de la ruta más corta (por ejemplo, milisegundos de retardo en comparación con el costo monetario). Como no se compararán los pesos entre las redes, las rutas más cortas en la interred no estarán bien definidas.

O peor aún, tal vez un operador no quiera que otro conozca siquiera los detalles de las rutas en su red, quizá debido a que los pesos y las rutas puedan reflejar información delicada (como el costo monetario) que representa una ventaja comercial competitiva.

Por último, la interred puede ser mucho más grande que cualquiera de las redes que la conforman. Por lo tanto, puede requerir algoritmos de enrutamiento que escalen bien mediante el uso de una jerarquía, incluso si ninguna de las redes individuales necesita usar una jerarquía.

Todas estas consideraciones conducen a un algoritmo de enrutamiento de dos niveles. Dentro de cada red, se utiliza un protocolo** intradominio** o de **puerta de enlace interior** para el enrutamiento (“puerta de enlace” es un término antiguo para “enrutador”). Podría ser un protocolo de estado del enlace del tipo que ya hemos descrito. A través de las redes que conforman la interred se utiliza un **protocolo interdominio** o de **puerta de enlace exterior**. Todas las redes pueden usar distintos protocolos intradominio, pero deben usar el mismo protocolo interdominio. En Internet, el protocolo de enrutamiento interdominio se denomina **[[BGP]] (Border Gateway Protocol)**.

> **Definición de Sistema Autónomo (AS):** Como cada red se opera de manera independiente a las demás, se conoce comúnmente como un AS. Una red de un ISP es un buen modelo mental de un AS. De hecho, una red de ISP puede estar compuesta por más de un AS en caso de ser administrada, o, si ha sido adquirida, por múltiples redes. Pero en general, la diferencia no es importante

### Fragmentación de paquetes
Cada red o enlace impone un tamaño máximo a sus paquetes. Estos límites tienen varias razones, entre ellas: 
1. El hardware (por ejemplo, el tamaño de una trama Ethernet). 
2. El sistema operativo (por ejemplo, todos los búferes son de 512 bytes). 
3. Los protocolos (por ejemplo, la cantidad de bits en el campo de longitud de paquete). 
4. El cumplimiento de algún estándar (inter)nacional. 
5. El deseo de reducir hasta cierto nivel las retransmisiones inducidas por errores. 
6. El deseo de evitar que un paquete ocupe el canal demasiado tiempo.

Por lo general, los hosts prefieren transmitir paquetes grandes, ya que esto reduce las sobrecargas de paquetes, como el ancho de banda desperdiciado en los bytes de encabezado. Surge un problema obvio de interconexión de redes cuando un paquete grande quiere viajar a través de una red cuyo tamaño máximo de paquete es muy pequeño. Esta molestia ha sido una cuestión persistente; y las soluciones han evolucionado junto con toda la experiencia que se ha obtenido gracias a [[Internet]].

Una solución es asegurar que no ocurra el problema en primer lugar. Sin embargo, es más fácil decir esto que hacerlo. Por lo general, una fuente no conoce la ruta que tomará un paquete a través de la red hacia un destino, por lo que en definitiva no sabe qué tan pequeños deben ser los paquetes para llegar ahí. A este tamaño de paquete se le conoce como **MTU de la ruta (Maximum Transmission Unit)**. Incluso si la fuente conociera el MTU de la ruta, los paquetes se enrutan de manera independiente en una red sin conexión como Internet. Este enrutamiento significa que las rutas pueden cambiar de repente, lo que a su vez puede cambiar de manera inesperada el MTU de la ruta.

La solución alternativa al problema es permitir que los enrutadores dividan los paquetes en fragmenos y envíen cada uno como un paquete de red separado. Sin embargo es mucho más fácil convertir un objeto grande en pequeños fragmentos que el proceso inverso. Las redes de conmutación de paquetes también tienen problemas al unir nuevamente los fragmentos.

Existen dos estrategias opuestas para recombinar los fragmentos de vuelta en el paquete original. La primera es hacer que la fragmentación producida por una red de “pequeños paquetes” sea transparente para cualquier red subsecuente por la que deba pasar el paquete en su camino hacia el destino final. En este método, cuando un paquete de tamaño excesivo llega a G1, el enrutador lo divide en fragmentos. Cada fragmento es dirigido al mismo enrutador de salida, G2, en donde se recombinan las piezas. De esta manera se ha hecho transparente el paso a través de la red de paquete pequeño. Las redes subsecuentes ni siquiera se enteran de que ha ocurrido una fragmentación.

La fragmentación transparente es sencilla, pero tiene algunos problemas. Por una parte, el enrutador de salida debe saber cuándo ha recibido todas las piezas, por lo que debe incluirse un campo de conteo o un bit de “fin de paquete”. Además, como todos los paquetes deben salir por el mismo enrutador para volver a ensamblarlos, las rutas están restringidas. Al no permitir que algunos fragmentos sigan una ruta al destino final, y otros fragmentos una ruta distinta, puede bajar un poco el desempeño. Lo más importante es la cantidad de trabajo que el enrutador tenga que llevar a cabo. Tal vez necesite colocar los fragmentos en un búfer a medida que vayan llegando, para después decidir cuándo debe descartarlos si no llegan todos los fragmentos. Parte de este trabajo también podría ser un desperdicio, ya que el paquete puede pasar a través de una serie de pequeñas redes de paquetes, y tal vez haya que fragmentarlo y recombinarlo repetidas veces.

La otra estrategia de fragmentación es abstenerse de recombinar los fragmentos en los enrutadores intermedios. Una vez que se ha fragmentado un paquete, cada fragmento se trata como si fuera un paquete original. La recombinación ocurre sólo en el host de destino.

La principal ventaja de la fragmentación no transparente es que los enrutadores tienen que trabajar menos. [[IP]] funciona de esta manera. Un diseño completo requiere que los fragmentos se enumeren de tal forma que se pueda reconstruir el flujo de datos original. El diseño utilizado por IP es proporcionar a cada fragmento un número de paquete (que todos los paquetes transportan), un desplazamiento de bytes absoluto dentro del paquete, y una bandera que indica si es el final del paquete.

Por desgracia, este diseño aún tiene problemas. La sobrecarga puede ser mayor que con la fragmentación transparente, ya que los encabezados de los fragmentos ahora se transportan a través de algunos enlaces en donde tal vez no sean necesarios. Pero el verdadero problema es la existencia de los fragmentos en primera instancia. Kent y Mogul (1987) argumentaron que la fragmentación es perjudicial para el desempeño, ya que al igual que las sobrecargas de los encabezados, un paquete completo se extravía si cualquiera de sus fragmentos se pierde, y porque la fragmentación representa una carga para los hosts más grande de lo que se tenía pensado originalmente.

Esto nos conduce de vuelta a la solución original de deshacernos de la fragmentación en la red, la estrategia que se utiliza en la Internet moderna. Al proceso se le conoce como **descubrimiento de MTU de la ruta**. En este cada paquete IP se envía con sus bits de encabezado establecidos para indicar que no se puede realizar ningún tipo de fragmentación. Si un enrutador recibe un paquete demasiado grande, genera un paquete de error, lo devuelve a la fuente y descarta el paquete. Cuando el origen recibe el paquete de error, usa la información interna para volver a fragmentar el paquete en piezas que sean lo bastante pequeñas como para que el enrutador las pueda manejar. Si un enrutador más adelante en la ruta tiene una MTU aún más pequeña, se repite el proceso.

La desventaja del descubrimiento de MTU de la ruta es que puede haber retardos iniciales adicionales sólo por enviar un paquete. Tal vez sea necesario más de un retardo de ida y vuelta para sondear la ruta y encontrar la MTU antes de entregar datos al destino.