Modelo de optimización: 
1. Problema
2. El problema representado en parámetros
3. Función de evaluación
# Redes neuronales
Las sinapsis tienen un peso que define que tan _fuerte_ es la relación entre la entrada y la neurona. La suma del producto de las entradas con su propio peso se compara contra un umbral que llamamos _bias_ si lo supera es positivo, sino es negativo.
$$y = \sum_{i=1}^{D}{w_i x_i}-b = \sum_{i=1}^{D}{w_i x_i}+b$$
En general se busca mantener todas las entradas dentro de un mismo rango numérico para generar buenos resultados. Para esto se pueden normalizar las entradas estadísticamente.
$$  
y = \sum_{i=1}^{D}{w_i x_i}+b = [w_1\ w_2\ \dots\ w_D]*
  \begin{bmatrix}
   x_1\\
   x_2\\
   \vdots\\
   x_D
 \end{bmatrix}
 + b
 = [w_1\ w_2\ \dots\ w_D\ b]*
  \begin{bmatrix}
   x_1\\
   x_2\\
   \vdots\\
   x_D\\
   1
 \end{bmatrix}
 = W^*X^*
 $$
Para entrenar la red necesito datos clasificados (por eso es supervisado). El proceso es agarrar dato a dato y ajustar los parámetros de los perceptrones para llegar al resultado deseado. Este proceso debe realizar cambios de forma controlada para evitar arruinar los ajustes anteriores.

Una vez que se procesan todos los datos se dice que concurrió una _epoch_ y se vuelve a empezar hasta llegar a un resultado satisfactorio. En el caso del perceptrón simple no se permite error.
$$W_n = W_{n-1} + \Delta W_n\ ;\ \Delta W_n = \eta* e* X^T \\
$$
En estas ecuaciones n representa un dato siendo procesado, $\eta$: _learning rate_ ; e: error.

Un perceptrón simple solo puede separar un conjunto de datos que sea linealmente separable.

Una alternativa a entrenar la red pasando de a un dato y modificando según su error (entrenamient _on line_) es realizar un entrenamiento por _batch_. En los entrenamientos _batch_ acumulamos los errores y modificamos el perceptrón solo al final de procesar todo un _batch_. El entrenamiento _on line_ no tiene ventajas respecto al _batch_ así que se usa el segundo que requiere menos tiempo de procesamiento.