$$y = \varphi(v) = \varphi(\sum_{i=1}^{D}{w_i x_i}+b)$$
$\varphi$ es la función de activación y puede ser muchas funciones, la más usada actualmente es ReLU. Pero también se usan frecuentemente la tangente hipervólica y la sigmoidea.
# Redes neuronales FeedForward FullyConected (Dense) (FF-FC)
En una red neuronal la salida de una neurona se pasa como entrada de otra neurona. En el caso de la feedforward la información va de izquierda a derecha y en ningún momento vuelve hacia atrás. 

Las redes neuronales se ordenan en capas. Todas las entradas se ingresan en todas las neuronas de la primera capa oculta, las salidas de la primer capa oculta pasan como entradas de todas las neuronas de la segunda capa oculta y así hasta llegar a la última capa que se llama capa de salida.

Si se usa un red neuronal para regresión se aconseja que la función de activación de la capa de salida sea lineal ($\varphi(v) = v$) y que esta contnenga una sola neurona. Para entrenamiento se puede usar el error cuadrático medio (MSE)

Si se usa para clasificación se aconseja _one hot encoding_ donde se tiene una neurona de salida por cada clase posible, donde un 1 indica que la clase es la correcta y un 0 que no. A veces se recomienda usar como función de activación la función sigmoide. Para evitar tener errores en la capa de salida se suele agregar una capa de cómputo luego de la capa de salida (SOFTMAX) para que las salidas se regularizen.
$$ SOFTMAX(y_i) = \frac{e^{y_i}}{\sum^{N_n}_{j=1}e^{y_j}}$$
Al momento de entrenar una red de clasificación el error se puede calcular como la _cross entropy_.
## Implementar una red
1. Definir la arquitectura (número de capas, funciones de activación y capas de cómputo).
2. Entrenar la red (_backpropagation_)

No se suelen iniciar los pesos en cero porque relentiza el entrenamiento.
Si una red se entrena hasta llegar a error cero pierde su capacidad de generalización (_overfitting_).
## Overfitting
Un método para evitar el overfitting es evaluar la red con datos que no estén en el conjunto de entrenamiento cada cierta cantidad de _epochs_. Los datos de prueba (_test data_) son del mismo tipo y origen que los datos de entrenamiento (_training data_). El error al realizar la evaluación se utiliza como criterio de corte. Este método se llama _hold out_.

Este proceso se realiza varias veces para asegurarse que el conjunto de _test data_ sea representativo. Entonces se registran las cantidades de _epoch_, los errores de _train_ y _test_ a partir de estos podemos tener un promedio de error con su desviación. Luego se vuelve a hacer el proceso con todos los datos y se corta en el error promedio o usando el dato de las _epoch_ promedio.