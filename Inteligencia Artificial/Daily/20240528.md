# Deconvolution (Convolución inversa)
Transforma el espacio latente en lo que nosotros queramos. Para incrementar las dimensiones de un tensor podemos usar distintos modos de upsampling, como la convolución traspuesta.

# Autoencoder
Se entrena un encoder que convierte una entrada a un espacio latente junto a un decoder que convierte ese espacio latente a la misma entrada. De aquí se obtiene un encoder muy bueno.

# Generative Adversarial Networks (GAN)
Partes de una GAN:
- El **discriminador** aprende a identificar imágenes generadas de imágenes reales. El discriminador se entrena brindandole imagenens reales e imagenes generadas y buscando que las clasifique correctamente.
- El **generador** parte de un espacio latente que es ruido y va a generar una imagen. La forma de entrenar al generador es buscar que las imágenes generadas confundan al discriminador.

## Conditional GAN (CGAN)
Ahora buscamos un generador al que le podamos pedir que genere un elemento particular de un conjunto dado. Para esto vamos a necesitar añadir el dato de lo que se busca generar al ruido que alimenta el generador y añadir el dato de lo que son cada foto que entra el disciminador, sea real o sintética (para esto se puede usar one shot encoding).
Durante el entrenamiento se añade al vector de ruido un dato que particulariza el tipo de resultado a generar. Y para alimentar el discriminador se puede utilizar una red neuronal que transforme el dato en un vector de MxM para ser concatenada a la imagen como una canal más. Esta red neuronal se entrena en ambos pasos (tanto como cuando se entrena el discriminador como cuando se entrena el generador).
